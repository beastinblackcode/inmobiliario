# üè† Madrid Real Estate Tracker

**Monitorizaci√≥n diaria del mercado inmobiliario de Madrid**

Sistema completo de scraping, an√°lisis y visualizaci√≥n del mercado de venta de viviendas en Madrid a trav√©s del portal Idealista.

## üìã Caracter√≠sticas

- ‚úÖ **Scraping Inteligente**: Recorre los 21 distritos de Madrid individualmente para evitar l√≠mites de paginaci√≥n
- ‚úÖ **Detecci√≥n de Ventas**: Identifica propiedades vendidas/retiradas por desaparici√≥n de anuncios
- ‚úÖ **Proxy Integration**: Usa Bright Data Web Unlocker API para evitar bloqueos
- ‚úÖ **Base de Datos SQLite**: Persistencia local con historial completo
- ‚úÖ **Dashboard Interactivo**: Visualizaci√≥n con Streamlit y gr√°ficos interactivos
- ‚úÖ **An√°lisis Temporal**: Seguimiento de evoluci√≥n de precios y tiempo en mercado

## üèóÔ∏è Arquitectura

```
inmobiliario/
‚îú‚îÄ‚îÄ database.py          # Gesti√≥n de SQLite y operaciones CRUD
‚îú‚îÄ‚îÄ scraper.py          # Motor de scraping con BeautifulSoup
‚îú‚îÄ‚îÄ app.py              # Dashboard de Streamlit
‚îú‚îÄ‚îÄ requirements.txt    # Dependencias Python
‚îú‚îÄ‚îÄ .env.example        # Plantilla de configuraci√≥n
‚îú‚îÄ‚îÄ .env               # Credenciales (crear manualmente)
‚îî‚îÄ‚îÄ real_estate.db     # Base de datos (generada autom√°ticamente)
```

## üöÄ Instalaci√≥n

### 1. Clonar/Descargar el Proyecto

```bash
cd /Users/luisnuno/Downloads/workspace/inmobiliario
```

### 2. Crear Entorno Virtual (Recomendado)

```bash
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar Bright Data

1. Crea una cuenta en [Bright Data](https://brightdata.com)
2. Configura un Web Unlocker zone
3. Obt√©n tus credenciales (username, password, host)
4. Copia `.env.example` a `.env`:

```bash
cp .env.example .env
```

5. Edita `.env` con tus credenciales reales:

```env
BRIGHTDATA_USER=brd-customer-hl_xxxxx-zone-xxxxx
BRIGHTDATA_PASS=your_password_here
BRIGHTDATA_HOST=brd.superproxy.io:33335
```

## üìä Uso

### Ejecutar el Scraper

El scraper debe ejecutarse diariamente para mantener los datos actualizados:

```bash
python scraper.py
```

**Duraci√≥n estimada**: 30-60 minutos (depende de la cantidad de anuncios y velocidad del proxy)

**Proceso**:
1. Inicializa la base de datos si no existe
2. Carga IDs activos existentes
3. Recorre los 21 distritos de Madrid
4. Para cada distrito, pagina hasta el final
5. Extrae y parsea todos los anuncios
6. Actualiza la base de datos (inserta nuevos, actualiza existentes)
7. Marca como vendidos los anuncios que desaparecieron

### Lanzar el Dashboard

```bash
streamlit run app.py
```

El dashboard se abrir√° autom√°ticamente en tu navegador (por defecto: `http://localhost:8501`)

## üìà Funcionalidades del Dashboard

### Filtros Interactivos (Sidebar)
- **Estado**: Activos / Vendidos / Todos
- **Distritos**: Selecci√≥n m√∫ltiple de los 21 distritos
- **Rango de Precio**: M√≠nimo y m√°ximo
- **Tipo de Vendedor**: Particular / Agencia / Todos

### M√©tricas Principales (KPIs)
- Precio Medio Total
- Precio Medio por m¬≤
- Total de Inmuebles Activos
- Vendidos en los √∫ltimos 30 d√≠as

### Tablas
- Top 10 Barrios M√°s Caros
- Top 10 Barrios M√°s Baratos

### Visualizaciones
- **Histograma**: Distribuci√≥n de precios
- **Gr√°fico de Barras**: Precio medio por distrito
- **Gr√°fico de Barras**: Tiempo medio en mercado (propiedades vendidas)
- **Gr√°fico de L√≠nea**: Evoluci√≥n temporal del precio medio

### Tabla de Datos Detallados
Vista completa de todas las propiedades con filtros aplicados

## üóÑÔ∏è Esquema de Base de Datos

```sql
CREATE TABLE listings (
    listing_id TEXT PRIMARY KEY,        -- ID √∫nico de Idealista
    title TEXT,                         -- T√≠tulo del anuncio
    url TEXT,                           -- URL completa
    price INTEGER,                      -- Precio en euros
    distrito TEXT,                      -- Distrito de Madrid
    barrio TEXT,                        -- Barrio/zona
    rooms INTEGER,                      -- N√∫mero de habitaciones
    size_sqm REAL,                      -- Superficie en m¬≤
    floor TEXT,                         -- Planta
    orientation TEXT,                   -- Interior/Exterior
    seller_type TEXT,                   -- Particular/Agencia
    is_new_development BOOLEAN,         -- Obra nueva
    first_seen_date TEXT,               -- Primera vez detectado
    last_seen_date TEXT,                -- √öltima vez visto
    status TEXT                         -- active/sold_removed
)
```

## üéØ Estrategia de Scraping

### Problema: L√≠mite de Paginaci√≥n
Idealista limita los resultados a **60 p√°ginas** (~1800 inmuebles) por b√∫squeda. Buscar "Madrid completo" perder√≠a miles de propiedades.

### Soluci√≥n: Scraping por Distritos
El scraper itera por los **21 distritos** de Madrid individualmente:

1. Centro
2. Arganzuela
3. Retiro
4. Salamanca
5. Chamart√≠n
6. Tetu√°n
7. Chamber√≠
8. Fuencarral-El Pardo
9. Moncloa-Aravaca
10. Latina
11. Carabanchel
12. Usera
13. Puente de Vallecas
14. Moratalaz
15. Ciudad Lineal
16. Hortaleza
17. Villaverde
18. Villa de Vallecas
19. Vic√°lvaro
20. San Blas-Canillejas
21. Barajas

Cada distrito se pagina completamente, garantizando cobertura total del mercado.

## üîç Detecci√≥n de Ventas

**Algoritmo ETL**:
1. Al iniciar, carga todos los IDs activos en memoria
2. Durante el scrape:
   - Si un ID **no existe** en BD ‚Üí INSERT (nuevo anuncio)
   - Si un ID **ya existe** ‚Üí UPDATE `last_seen_date` y precio
3. Al finalizar:
   - IDs que **no fueron vistos** ‚Üí Marcar como `sold_removed`
   - **M√©trica de venta**: `last_seen_date - first_seen_date` = d√≠as en mercado

**Nota**: "Vendido" incluye ventas reales, retiradas, y cambios a alquiler. No distingue entre estos casos.

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Rate Limiting
El scraper incluye delays entre requests:
- 1 segundo entre p√°ginas del mismo distrito
- 2 segundos entre distritos

Ajusta en `scraper.py` si experimentas bloqueos:
```python
time.sleep(1)  # L√≠nea 283
time.sleep(2)  # L√≠nea 327
```

### Timeout de Requests
Por defecto: 60 segundos. Ajusta si tienes conexi√≥n lenta:
```python
timeout=60  # L√≠nea 95 en scraper.py
```

### Cach√© del Dashboard
Los datos se cachean 5 minutos. Cambia en `app.py`:
```python
@st.cache_data(ttl=300)  # 300 segundos = 5 minutos
```

## ü§ñ Automatizaci√≥n (Opcional)

### Cron Job (Linux/Mac)

Ejecutar diariamente a las 3 AM:

```bash
crontab -e
```

A√±ade:
```
0 3 * * * cd /Users/luisnuno/Downloads/workspace/inmobiliario && /path/to/venv/bin/python scraper.py >> scraper.log 2>&1
```

### Task Scheduler (Windows)

1. Abre "Programador de tareas"
2. Crear tarea b√°sica
3. Trigger: Diario a las 3:00 AM
4. Acci√≥n: Ejecutar `python.exe scraper.py`

## üìù Campos Extra√≠dos

| Campo | Selector CSS | Procesamiento |
|-------|-------------|---------------|
| `listing_id` | `article[data-element-id]` | Atributo directo |
| `title` | `a.item-link` | Texto |
| `url` | `a.item-link[href]` | Concatenar con BASE_URL |
| `price` | `span.item-price` | Limpiar "‚Ç¨" y puntos ‚Üí int |
| `rooms` | `span.item-detail` (contiene "hab") | Extraer n√∫mero |
| `size_sqm` | `span.item-detail` (contiene "m¬≤") | Extraer float |
| `floor` | `span.item-detail` (contiene "Planta") | Texto completo |
| `orientation` | `span.item-detail` (interior/exterior) | Texto |
| `seller_type` | `span.logo-branding` | Existe ‚Üí Agencia, No ‚Üí Particular |
| `is_new_development` | `span.item-new-construction` | Boolean |

## ‚ö†Ô∏è Consideraciones √âticas

- **Respeta los T√©rminos de Servicio** de Idealista
- **Rate Limiting**: No sobrecargues sus servidores
- **Uso Personal**: Este proyecto es para an√°lisis personal/educativo
- **No Redistribuyas** datos scrapeados p√∫blicamente
- **Bright Data**: Aseg√∫rate de cumplir con sus pol√≠ticas de uso

## üêõ Troubleshooting

### Error: "Bright Data credentials not configured"
- Verifica que `.env` existe y contiene las credenciales correctas
- Aseg√∫rate de que `python-dotenv` est√° instalado

### Error: "No hay datos disponibles"
- Ejecuta primero `python scraper.py` para poblar la base de datos
- Verifica que `real_estate.db` existe en el directorio

### Dashboard no muestra gr√°ficos
- Verifica que hay suficientes datos (al menos 10-20 propiedades)
- Revisa que los filtros no est√°n excluyendo todos los datos

### Scraper se bloquea/falla
- Verifica credenciales de Bright Data
- Revisa el saldo de tu cuenta Bright Data
- Aumenta los delays entre requests
- Revisa logs para errores espec√≠ficos

## üìö Dependencias

- **requests**: HTTP requests con soporte de proxies
- **beautifulsoup4**: Parsing de HTML
- **streamlit**: Framework de dashboard
- **pandas**: Manipulaci√≥n de datos
- **plotly**: Gr√°ficos interactivos
- **python-dotenv**: Gesti√≥n de variables de entorno

## üìÑ Licencia

Este proyecto es de c√≥digo abierto para uso educativo y personal.

## ü§ù Contribuciones

Mejoras sugeridas:
- [ ] Notificaciones por email cuando se detectan nuevas propiedades
- [ ] Exportaci√≥n de datos a CSV/Excel
- [ ] An√°lisis de cambios de precio hist√≥ricos
- [ ] Integraci√≥n con otros portales (Fotocasa, etc.)
- [ ] API REST para acceso program√°tico
- [ ] Machine Learning para predicci√≥n de precios

## üìß Soporte

Para problemas o preguntas, revisa:
1. Esta documentaci√≥n
2. Comentarios en el c√≥digo fuente
3. Logs de ejecuci√≥n (`scraper.log` si configuraste cron)

---

**Desarrollado con ‚ù§Ô∏è para el an√°lisis del mercado inmobiliario de Madrid**
